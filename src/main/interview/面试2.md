###  服务端安全   ###
  1.网关，鉴权，token，签名检验，同时加上时间戳，防止重放。
      用HTTPS通信，另外APP往服务器接口发送的参数带token，还要加上签名，服务器端验签名（以防参数被篡改），校验token；
      同时加上时间戳，防止重放。（签名算法、密钥的分配安全存储要设计好）
      对服务器接口要有监控，监控到异常情况要有处理方案。
  2.pod隔离，防火墙
  3.代码注入，sql注入相关
  4.加密，https，基于OAuth2协议，进行URL签名 ===> URL签名只能垂直权限管理，但没法保护敏感数据


###  高性能设计  ###
  1.使用高性能IO，  高性能序列化，   在网络传输中使用双工通信协议可以获得比单工通信更高的吞吐量
  2.均衡使用CPU多核处理能力，代码中线程池，多线程使用； 计算密集型/IO密集型，设置合理的线程池参数。
    高效合理地使用和控制内存，代码
  3.最大化磁盘IOPS和吞吐，异步化处理： 比如mysql的redoLog，将多次随机的读写合并成一次读写
  4.小包 跑满万兆网卡，中断平衡。   ==> 合理选择传输数据的包，组合传送收发，

  5.建立长连接。减少反复的创建和销毁连接行为。但是，连接的保持是会占用Web系统服务端资源的，如果不充分使用这个连接，会导致资源浪费
    预加载技术，路由计划表，缓存资源

    2）数据库读写分离，集群，分库拆分，MySQL数据同步是通过binlog日志。延迟问题通过水平拆分服务来提高性能、多线程同步解决。
    3）nosql。NoSql数据库大量应用于微博系统等事务性不强的系统。如：BigTable、MongoDB 

C10K问题的解决方案
从网络编程技术的角度来说，主要思路：
  每个连接分配一个独立的线程/进程
  同一个线程/进程同时处理多个连接(I/O多路复用) epoll





为什么gts转数据。
  商品库数据，订单库数据，写入量非常大，分许多片，对其他业务组提供的服务有限。
  通过DTS数据流转，转存到mongo中，其他业务组，对数据非实时要求的，类似于计算的业务则通过mongo来完成。
  而对于订单消息有实时要求的，通过订阅订单发出的消息来完成一部解耦，避免订单库被拉垮。



consul+k8s动态负载均衡项目 

大家好,  针对目前发版 5xx 问题及随着业务增长可能存在的隐患, 运维团队计划启动 tengine+consul 的K8S动态负载均衡改造项目, 主要是为了解决以下4个问题:

1、服务发版出现 502 错误；
2、tengine 到 slb 单点问题；
3、slb 配额问题及 slb 维护成本问题；
4、kube-proxy iptables 模式性能问题；



领域模型
  业务角色和业务实体之间应该如何联系和协作以执行业务的一种抽象
  领域模型是一个分析模型，帮助系统分析人员、用户认识现实业务的工具，描述的是业务中涉及到的实体及其相互之间的关系，它是需求分析的产物，与问题域相关。

mysql 间隙锁，
https://mp.weixin.qq.com/s/Gc2MifYwxsfbOtoM22cM_w



目前scm-vpcprod线上因出现过Metaspace oom，需要进行优化，目前初步定位是由于jdk1.8中，jvm将类以及代码区域存放到Metaspace中，
而目前Metaspace区域的参数设置有些问题，线上将最大的和初始的Metaspace参数设置为相同的，这会导致Metaspace区域的在到达最大值时，
才会进行回收，并且目前线上使用了CMS的GC算法，这会导致GC线程和用户线程并行执行，如果Metaspace在最大时进行回收的时候，用户线程
继续申请类加载，则可能会导致Metaspace出现oom。
    特申请将scm-vpcprod应用的ecs机器：172.30.1.157的启动参数：
-XX:MetaspaceSize
-XX:MaxMetaspaceSize
设置为：-XX:MetaspaceSize=220M -XX:MaxMetaspaceSize=512M
目的是观察jvm的Metaspace区域是否能够被控制在220M以内。观察一周后如果达到效果，则全量机器都替换成此参数。




G1 复制算法 or 数组 mkdir


https://www.cnblogs.com/aspirant/p/8662690.html
https://www.cnblogs.com/aspirant/p/7200523.html
https://www.cnblogs.com/aspirant/p/8663872.html


5.Hystrix通过为每个依赖服务分配独立的线程池进行资源隔离，从而避免整个服务雪崩。这样做带来的代价就是维护多个线程池需要额外的性能开销。
雪崩效应常见场景
硬件故障：如服务器宕机，机房断电，光纤被挖断等。
流量激增：如异常流量，重试加大流量等。
缓存穿透：一般发生在应用重启，所有缓存失效时，以及短时间内大量缓存失效时。大量的缓存不命中，使请求直击后端服务，造成服务提供者超负荷运行，引起服务不可用。
程序BUG：如程序逻辑导致内存泄漏，JVM长时间FullGC等。
同步等待：服务间采用同步调用模式，同步等待造成的资源耗尽。


线程隔离-线程池
Hystrix通过命令模式对发送请求的对象和执行请求的对象进行解耦，将不同类型的业务请求封装为对应的命令请求。如订单服务查询商品，查询商品请求->商品Command；商品服务查询库存，查询库存请求->库存Command。并且为每个类型的Command配置一个线程池，当第一次创建Command时，根据配置创建一个线程池，并放入ConcurrentHashMap，

通常情况下，线程池引入的开销足够小，不会有重大的成本或性能影响。但对于一些访问延迟极低的服务，如只依赖内存缓存，线程池引入的开销就比较明显了，这时候使用线程池隔离技术就不适合了，
我们需要考虑更轻量级的方式，如信号量隔离。

public QueryByOrderIdCommandSemaphore(OrderServiceProvider orderServiceProvider) {
        super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("orderService"))
                .andCommandKey(HystrixCommandKey.Factory.asKey("queryByOrderId"))
                .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()
                        .withCircuitBreakerRequestVolumeThreshold(10)////至少有10个请求，熔断器才进行错误率的计算
                        .withCircuitBreakerSleepWindowInMilliseconds(5000)//熔断器中断请求5秒后会进入半打开状态,放部分流量过去重试
                        .withCircuitBreakerErrorThresholdPercentage(50)//错误率达到50开启熔断保护
                        .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE)
                        .withExecutionIsolationSemaphoreMaxConcurrentRequests(10)));//最大并发请求量
        this.orderServiceProvider = orderServiceProvider;
    }


Hystrix如何实现这些设计目标？
使用命令模式将所有对外部服务（或依赖关系）的调用包装在HystrixCommand或HystrixObservableCommand对象中，并将该对象放在单独的线程中执行；
每个依赖都维护着一个线程池（或信号量），线程池被耗尽则拒绝请求（而不是让请求排队）。
记录请求成功，失败，超时和线程拒绝。
服务错误百分比超过了阈值，熔断器开关自动打开，一段时间内停止对该服务的所有请求。
请求失败，被拒绝，超时或熔断时执行降级逻辑。
近实时地监控指标和配置的修改。



6.Zookeeper实现分布式锁原理	http://www.imooc.com/article/284956?block_id=tuijian_wz			临时顺序节点
使用zookeeper创建临时序列节点来实现分布式锁，适用于顺序执行的程序，大体思路就是创建临时序列节点，找出最小的序列节点，获取分布式锁，程序执行完成之后此序列节点消失，通过watch来监控节点的变化，从剩下的节点的找到最小的序列节点，获取分布式锁，执行相应处理，依次类推……

多个Jvm同时在Zookeeper上创建同一个相同的节点( /Lock)
zk节点唯一的！ 不能重复！节点类型为临时节点， jvm1创建成功时候，jvm2和jvm3创建节点时候会报错，该节点已经存在。这时候 jvm2和jvm3进行等待。
jvm1的程序现在执行完毕，执行释放锁。关闭当前会话。临时节点不复存在了并且事件通知Watcher，jvm2和jvm3继续创建。

大家都是上来直接创建一个锁节点下的一个接一个的临时顺序节点

如果自己不是第一个节点，就对自己上一个节点加监听器

只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制。

而且用临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队。



4.Redis 底层数据结构，分布式锁为何不可靠：主从模式下，同步数据未完成主挂，丢失。
Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，
并将 SDS 作为 Redis的默认字符串表示。

https://www.cnblogs.com/ysocean/p/9080942.html
Redis链表特性：
　　①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。
　　②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　　
　　③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。
　　④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。

⑤、渐近式 rehash
　　　　什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。




1.HashMap
	https://tech.meituan.com/2016/06/24/java-hashmap.html

下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。
因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，

这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。


2.不可不说的Java“锁”事
	https://tech.meituan.com/2018/11/15/java-lock.html

	CAS虽然很高效，但是它也存在三大问题，这里也简单说一下：

	a.ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成A，那么CAS进行检查时会发现值没有发生变化，
	但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。
JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。

 	b.循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。
	c.只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。
Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。

后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。


自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。

自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock，本文中仅做名词介绍，不做深入讲解，感兴趣的同学可以自行查阅相关资料。
CLH锁即Craig, Landin, and Hagersten (CLH) locks。CLH锁是一个自旋锁。能确保无饥饿性。提供先来先服务的公平性。
CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。

	Java对象头
	Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。

	Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。

	Monitor
	Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。
	Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

	现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。

3.	Spring IOC -bean对象的生命周期详解
	https://www.cnblogs.com/jasonZh/p/8762855.html

	1) spring对bean进行实例化,默认bean是单例
2) spring对bean进行依赖注入
3) 如果bean实现了BeanNameAware接口,spring将bean的id传给setBeanName()方法
4) 如果bean实现了BeanFactoryAware接口,spring将调用setBeanFactory方法,将BeanFactory实例传进来
5) 如果bean实现了ApplicationContextAware()接口,spring将调用setApplicationContext()方法将应用上下文的引用传入
6) 如果bean实现了BeanPostProcessor接口,spring将调用它们的postProcessBeforeInitialization接口方法
7) 如果bean实现了InitializingBean接口,spring将调用它们的afterPropertiesSet接口方法,类似的如果bean使用了init-method属性声明了初始化方法,改方法也会被调用
8) 如果bean实现了BeanPostProcessor接口,spring将调用它们的postProcessAfterInitialization接口方法
9) 此时bean已经准备就绪,可以被应用程序使用了,他们将一直驻留在应用上下文中,直到该应用上下文被销毁
10) 若bean实现了DisposableBean接口,spring将调用它的distroy()接口方法。同样的,如果bean使用了destroy-method属性声明了销毁方法,则该方法被调用


4.IOC 源码解读：
https://javadoop.com/post/spring-ioc


https://www.jianshu.com/p/a77e64250a9e
而真正起作用的是doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args)方法。而在这个方法里面包含了三个重要的方法
createBeanInstance、populateBean、initializeBean，看过之前系列文章的人都知道这三个方法分别代表：创建实例、属性注入、方法回调，这是bean初始化的核心方法。

解决循环依赖
SpringIOC解决循环依赖的思路就是依靠缓存，同时还得引出个概念即早期暴露引用。我们知道在IOC容器里bean的初始化的过程分为三个步骤：创建实例、属性注入实例、回调实例实现的接口方法。
解决思路就在这：当我们创建实例与属性注入实例这俩个步骤之间的时候，我们引入缓存，将这些已经创建好但是并没有注入属性的实例放到缓存里，而这些放在缓存里但是没有被注入属性的实例对象，
就是解决循环依赖的方法，
singletonObjects		一级缓存		用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用
earlySingletonObjects	二级缓存		存放原始的 bean 对象（尚未填充属性），用于解决循环依赖
singletonFactories		三级缓存		存放 bean 工厂对象，用于解决循环依赖



public class ClassPathXmlApplicationContext extends AbstractXmlApplicationContext {
  private Resource[] configResources;
 
  // 如果已经有 ApplicationContext 并需要配置成父子关系，那么调用这个构造方法
  public ClassPathXmlApplicationContext(ApplicationContext parent) {
    super(parent);
  }
  ...
  public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent)
      throws BeansException {
 
    super(parent);
    // 根据提供的路径，处理成配置文件数组(以分号、逗号、空格、tab、换行符分割)
    setConfigLocations(configLocations);
    if (refresh) {
      refresh(); // 核心方法
    }
  }
    ...
}


@Override
public void refresh() throws BeansException, IllegalStateException {
   // 来个锁，不然 refresh() 还没结束，你又来个启动或销毁容器的操作，那不就乱套了嘛
   synchronized (this.startupShutdownMonitor) {
 
      // 准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符
      prepareRefresh();
 
      // 这步比较关键，这步完成后，配置文件就会解析成一个个 Bean 定义，注册到 BeanFactory 中，
      // 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了，
      // 注册也只是将这些信息都保存到了注册中心(说到底核心是一个 beanName-> beanDefinition 的 map)
      ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
 
      // 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean
      // 这块待会会展开说
      prepareBeanFactory(beanFactory);
 
      try {
         // 【这里需要知道 BeanFactoryPostProcessor 这个知识点，Bean 如果实现了此接口，
         // 那么在容器初始化以后，Spring 会负责调用里面的 postProcessBeanFactory 方法。】
 
         // 这里是提供给子类的扩展点，到这里的时候，所有的 Bean 都加载、注册完成了，但是都还没有初始化
         // 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事
         postProcessBeanFactory(beanFactory);
         // 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 方法
         invokeBeanFactoryPostProcessors(beanFactory);
 
         // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别
         // 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization
         // 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化
         registerBeanPostProcessors(beanFactory);
 
         // 初始化当前 ApplicationContext 的 MessageSource，国际化这里就不展开说了，不然没完没了了
         initMessageSource();
 
         // 初始化当前 ApplicationContext 的事件广播器，这里也不展开了
         initApplicationEventMulticaster();
 
         // 从方法名就可以知道，典型的模板方法(钩子方法)，
         // 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前）
         onRefresh();
 
         // 注册事件监听器，监听器需要实现 ApplicationListener 接口。这也不是我们的重点，过
         registerListeners();
 
         // 重点，重点，重点
         // 初始化所有的 singleton beans
         //（lazy-init 的除外）
         finishBeanFactoryInitialization(beanFactory);
 
         // 最后，广播事件，ApplicationContext 初始化完成
         finishRefresh();
      }
 
      catch (BeansException ex) {
         if (logger.isWarnEnabled()) {
            logger.warn("Exception encountered during context initialization - " +
                  "cancelling refresh attempt: " + ex);
         }
 
         // Destroy already created singletons to avoid dangling resources.
         // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源
         destroyBeans();
 
         // Reset 'active' flag.
         cancelRefresh(ex);
 
         // 把异常往外抛
         throw ex;
      }
 
      finally {
         // Reset common introspection caches in Spring's core, since we
         // might not ever need metadata for singleton beans anymore...
         resetCommonCaches();
      }
   }
}

===========================================================================================================================================================
scm-cm-gateway-mobile 里面

比如一个跨域请求，[option + post]

Option请求一定要返回跨域相关的信息：
  Access-Control-Allow-Origin等相关信息，参照org.springframework.http.HttpHeaders
    org.springframework.web.cors.reactive.DefaultCorsProcessor
接下来的请求才会成功。

在Spring的WebFlux编程中，
  1. WebFilter本身是容器类型的拦截，  应优先处理，但是如果想允许跨域，应返回跨域的header信息之后，再执行链路。
        ServerWebExchange exchange, WebFilterChain chain   ==> chain.filter(exchange);
  
  2. GlobalFilter则是spring-cloud-gateway的拦截。
        ServerWebExchange exchange, GatewayFilterChain chain  ==> chain.filter(exchange);


一个包含跨域的，供参考的 application.yml 配置： 

spring:
  mvc:
    date-format: 'yyyy-MM-dd HH:mm:ss'
  jackson:
    date-format: 'yyyy-MM-dd HH:mm:ss'
    time-zone: 'GMT+8'
  http:
    converters:
      preferred-json-mapper: gson
  cloud:
    gateway:
      globalcors:
        corsConfigurations:
          '[/**]':
            allowedOrigins: '*'
            allowedHeaders: '*'
            allowedMethods: '*'
            maxAge: 18000
            allowCredentials: true
      httpclient:
        ssl:
          handshakeTimeout: 10000
          closeNotifyFlushTimeout: 3000
      discovery:
        locator:
          enabled: false
          lowerCaseServiceId: true
      routes:
        - id: scm-cm-public
          uri: lb://scm-cm-public
          predicates:
            - Path=/scm-cm-public/**
        - id: scm-weigh
          uri: lb://scm-weigh
          predicates:
            - Path=/scm-weigh/**
        - id: scm-api
          uri: lb://scm-api #http://localhost:8990
          predicates:
            - Path=/scm_kry/**
===========================================================================================================================================================










