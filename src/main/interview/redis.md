浅谈Redis中的Rehash机制       渐进式哈希(rehashing)  
 https://blog.csdn.net/cqk0100/article/details/80400811 
 
 
 Redis 6 引入的[多线程IO 特性]对性能提升至少是一倍以上
 
 
为什么Redis的读写性能这么高呢？原因有许多，我们列举主要的三个：
1、Redis基于内存操作：
    绝大部分的请求为纯粹的内存操作，而且使用hash结构存储数据，查找和操作的时间复杂度均为O(1)。

2、Redis数据结构简单：
    redis对数据的操作还是比较简单的，而且redis的数据结构是专门设计的。

3、单线程-IO多路复用模型：
    单线程的设计省去了很多的麻烦：比如上下文切换、资源竞争、CPU切换消耗以及各种锁操作等等问题，而IO多路复用模型的使用更让Redis提升了效率。

 ==========
     https://segmentfault.com/a/1190000018887256
     ##Redis的数据结构##
 之前是[sds]==>Redis_ENCODING_RAW ，现在是Redis_String
 [字符串对象]的编码可以是int、raw或者embstr
     如果一个字符串的内容可以转换为long，那么该字符串就会被转换成为long类型，对象的ptr就会指向该long，并且对象类型也用int类型表示。
     普通的字符串有两种，embstr和raw。embstr应该是Redis 3.0新增的数据结构,在2.8中是没有的。
         如果字符串对象的长度小于39字节，就用embstr对象。否则用传统的raw对象。
     
   [1.embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为objet分配对象，embstr省去了第一次）。
      2.相对地，释放内存的次数也由两次变为一次。
        3.embstr的objet和sds放在一起，更好地利用缓存带来的优势。]
     raw和embstr的区别可以用下面两幅图所示：
 
 [列表对象]的编码可以是ziplist或者linkedlist
     ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。
         当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储。[但当数据量过大时就ziplist就不是那么好用了。]
         因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。
         如下图所示，对象结构中ptr所指向的就是一个ziplist整个ziplist只需要malloc一次，它们在[内存中是一块连续的区域]。
     linkedlist是一种双向链表。它的结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息。
         当每增加一个node的时候，就需要重新malloc一块内存。
 
 [哈希对象]的底层实现可以是ziplist或者hashtable。
     ziplist中的哈希对象是按照key1,value1,key2,value2这样的顺序存放来存储的。当对象数目不多且内容不大时，这种方式效率是很高的。
 
 [集合对象]的编码可以是intset或者hashtable
     #define INTSET_ENC_INT16 (sizeof(int16_t))  
     #define INTSET_ENC_INT32 (sizeof(int32_t))  
     #define INTSET_ENC_INT64 (sizeof(int64_t))  
     [intset是一个有序集合]，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作。
         比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，
             那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配，这时插入的复杂度就为O(N)了。
     intset不支持降级操作。
     
 [有序集合]的编码可能两种，一种是ziplist，另一种是skiplist与dict的结合。
     ziplist作为集合和作为哈希对象是一样的，member和score顺序存放。按照score从小到大顺序排列
     skiplist是一种跳跃表，它实现了有序集合中的快速查找，在大多数情况下它的速度都可以和平衡树差不多。但它的实现比较简单，可以作为平衡树的替代品。

Reactor模式详解
https://www.cnblogs.com/doit8791/p/7461479.html
   优点
     1）响应快，不必为单个同步时间所阻塞，虽然Reactor本身依然是同步的；
     2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；
     3）可扩展性，可以方便的通过增加Reactor实例个数来充分利用CPU资源；
     4）可复用性，reactor框架本身与具体事件处理逻辑无关，具有很高的复用性；
   缺点
     1）相比传统的简单模型，Reactor增加了一定的复杂性，因而有一定的门槛，并且不易于调试。
     2）Reactor模式需要底层的Synchronous Event Demultiplexer支持，比如Java中的Selector支持，操作系统的select系统调用支持，
         如果要自己实现Synchronous Event Demultiplexer可能不会有那么高效。
     3） Reactor模式在IO读写数据时还是在同一个线程中实现的，即使使用多个Reactor机制的情况下，
         那些共享一个Reactor的Channel如果出现一个长时间的数据读写，会影响这个Reactor中其他Channel的相应时间，
         比如在大文件传输时，IO操作就会影响其他Client的相应时间，因而对这种操作，使用传统的Thread-Per-Connection或许是一个更好的选择，
         或则此时使用Proactor模式。
 
 
以下是哈希表渐进式rehash的详细步骤：

1.为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。
2.在字典中维护一个rehashidx变量，来标记当前rehash到了ht[0] 的 dictEntry table哪个位置。
3.在渐进式rehash进行期间，每次对字典执行增删改查操作时，除了执行指定操作外，
    还要将ht[0]中的rehashidx索引位置上的键值对 rehash 到ht[1]上，当本次rehash完成时，rehashidx加一。
4.随着字典操作的不断进行，最终在某个时间点上，ht[0]上的键值对都 rehash 到了ht[1]上，这时程序将 rehashidx 设置为-1，
    表示 rehash 操作已经完成。
5.rehash 完所有键值对后，ht[1]和ht[0]将交换位置，即ht[1]将成为新的ht[0]。
    渐进式 rehash 采用了分治的思想，将 rehash 键值对所需的工作分摊到了每次对字典的增删改查操作上，
    虽然降低了 redis 服务器的整体吞吐量，但提升了响应速度，不会出现在某次操作时特别慢的情况。


 渐进式哈希的精髓在于：数据的迁移不是一次性完成的，而是可以通过dictRehash()这个函数分步规划的，
    并且调用方可以及时知道是否需要继续进行渐进式哈希操作。
    如果dict数据结构中存储了海量的数据，那么一次性迁移势必带来redis性能的下降，别忘了redis是单线程模型，
        在实时性要求高的场景下这可能是致命的。而渐进式哈希则将这种代价可控地分摊了，调用方可以在dict做插入，删除，
        更新的时候执行dictRehash()，最小化数据迁移的代价。
 在迁移的过程中，数据是在新表还是旧表中并不是一个非常急迫的需求，迁移的过程并不会丢失数据，在旧表中找不到再到新表中寻找就是了。 



https://www.jianshu.com/p/3335fab1c1f2  
redis系列之淘汰删除  

美团针对Redis Rehash机制的探索和实践  
https://www.cnblogs.com/meituantech/p/9376472.html  

Redis 高负载下的中断优化  
https://tech.meituan.com/2018/03/16/redis-high-concurrency-optimization.html  


https://blog.csdn.net/zhiguozhu/article/details/50517527  



List: 
    一个列表最多可以包含232-1个元素（4294967295，每个表超过40亿个元素）
    在社交网络中建立一个时间线模型，使用LPUSH去添加新的元素到用户时间线中，使用LRANGE去检索一些最近插入的条目
    你可以同时使用LPUSH和LTRIM去创建一个永远不会超过指定元素数目的列表并同时记住最后的N个元素
    列表可以用来当作消息传递的基元（primitive），例如，众所周知的用来创建后台任务的Resque Ruby库

Redis Hashes是字符串字段和字符串值之间的映射
    尽管Hashes主要用来表示对象，但它们也能够存储许多元素

Set Uniqe操作，
    获取某段时间所有数据排重值实时系统，反垃圾系统共同好友、二度好友利用唯一性，可以统计访问网站的所有独立 IP好友推荐的时候，
    根据 tag 求交集，大于某个 threshold 就可以推荐Hashes 
    可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。
    把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。
# 将一个set的元素移动到另外一个set
smove yourSet mySet 2

# 求两set的交集
sinter yourSet mySet

# 求两set的并集
sunion yourSet mySet

# 求在yourSet中而不在mySet中的元素
sdiff yourSet mySet    
    

Sorted Set 排行榜应用，取TOP N操作需要精准设定过期时间的应用（时间戳作为Score）带有权重的元素，
    比如一个游戏的用户得分排行榜过期项目处理，按照时间排序

Redis解决秒杀/抢红包等高并发事务活动
    秒杀开始前30分钟把秒杀库存从数据库同步到Redis Sorted Set
    用户秒杀库存放入秒杀限制数长度的Sorted Set
    秒杀到指定秒杀数后，Sorted Set不在接受秒杀请求，并显示返回标识
    秒杀活动完全结束后，同步Redis数据到数据库，秒杀正式结束  
    
    

分布式锁
https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-lock-redis-vs-zookeeper.md

①redis 最普通的分布式锁
    SET resource_name [my_random_value] NX PX 30000
    
-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
    if redis.call("get",KEYS[1]) == ARGV[1] then
        return redis.call("del",KEYS[1])
    else
        return 0
    end
    
NX：表示只有 key 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 nil）
PX 30000：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。
为啥要用 [my_random_value] 随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，
    此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 lua 脚本来释放锁。
 但是这样是肯定不行的。因为如果是普通的 redis 单实例，那就是单点故障。
 或者是 redis 普通主从，那 redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，
 别人就可以 set key，从而拿到锁。   
  
  
②RedLock 算法     https://redis.io/topics/distlock
    这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：
    1.获取当前时间戳，单位是毫秒；
    2.跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
    3.尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；
    4.客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
    5.要是锁建立失败了，那么就依次之前建立过的锁删除；
    6.只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。

③zk 分布式锁
zk 分布式锁，其实可以做的比较简单，就是某个节点尝试创建临时 znode，此时创建成功了就获取了这个锁；
    这个时候别的客户端来创建锁会失败，只能注册个监听器监听这个锁。
    释放锁就是删除这个 znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新加锁。
也可以采用另一种方式，创建临时顺序节点：
    如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；
    后面的每个人都会去监听排在自己前面的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 zookeeper 给通知，
    一旦被通知了之后，就 ok 了，自己就获取到了锁，就可以执行代码了。


redis 分布式锁和 zk 分布式锁的对比
    redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。
    zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。
另外一点就是，如果是 redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；
而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。

redis 分布式锁大家没发现好麻烦吗？遍历上锁，计算时间等等......zk 的分布式锁语义清晰实现简单。
所以先不分析太多的东西，就说这两点，我个人实践认为 zk 的分布式锁比 redis 的分布式锁牢靠、而且模型简单易用。




集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。
    集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。
    它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。
zookeeper-centralized-storage
    redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，
    让其它节点也进行元数据的变更。元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；
    不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。



一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，
    即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。

redis cluster 的 hash slot 算法
redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。
redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。
    hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，
    就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。
    客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。
    任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。

判断节点宕机
    如果一个节点认为另外一个节点宕机，那么就是 pfail，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是 fail，客观宕机，
    跟哨兵的原理几乎一样，sdown，odown。
    在 cluster-node-timeout 内，某个节点一直没有返回 pong，那么就被认为 pfail。
    如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。

从节点过滤
    对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。
    检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor，
    那么就没有资格切换成 master。

从节点选举
    每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。
    所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（N/2 + 1）都投票给了某个从节点，
    那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。
    与哨兵比较
    整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。


===============================
redis 过期策略是：定期删除+惰性删除。
    所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。
    内存淘汰机制: allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。


缓存雪崩的事前事中事后的解决方案如下。     缓存挂了，此时 1 秒 5000 个请求全部落数据库
    事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。
    事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
    事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

缓存穿透    黑客发出的那 4000 个攻击请求，缓存中查不到，每次你去数据库里查，也查不到。
    每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个过期时间，这样的话，
    下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。

缓存击穿
    缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，
    直接请求数据库，就像是在一道屏障上凿开了一个洞。
    ==> 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，
    再释放锁，进而其它请求才能通过该 key 访问数据。


===
RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储,  master 执行 bgsave ，在本地生成一份 rdb 快照文件。

优点：
RDB是一个非常紧凑的文件,它保存了某个时间点得数据集,非常适用于数据集的备份
RDB是一个紧凑的单一文件, 非常适用于灾难恢复
RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，
    所以RDB持久化方式可以最大化redis的性能
与AOF相比,在恢复大的数据集的时候，RDB方式会更快一些

缺点：
如果你希望在redis意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么RDB不适合，
    Redis要完整的保存整个数据集是一个比较繁重的工作
RDB 需要经常fork子进程来保存数据集到硬盘上,当数据集比较大的时候,fork的过程是非常耗时的,
    可能会导致Redis在一些毫秒级内不能响应客户端的请求.如果数据集巨大并且CPU性能不是很好的情况下,
    这种情况会持续1秒,AOF也需要fork,但是你可以调节重写日志文件的频率来提高数据集的耐久度

AOF持久化方式记录每次对服务器写的操作
redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整
优点
    使用AOF 会让你的Redis更加耐久: 你可以使用不同的fsync策略：无fsync,每秒fsync,每次写的时候fsync
    AOF文件是一个只进行追加的日志文件,所以不需要写入seek
    Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写
    AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单
缺点
    对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积
    根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB



缓存服务的更新策略有哪些？  
https://www.jianshu.com/p/22c7e9ab5d15    
  
缓存的过期时间问题：
设计缓存的过期时间需要非常的有技巧，且必须与业务实际情况相结合。
因为如果设计的过期时间太短了，那会导致缓存效果不佳，
且还会造成频繁的从数据库中往缓存里写数据。如果缓存设计的过期时间太长了，又会导致内存的浪费。

缓存的命中率问题：
这也是设计缓存中需要存放哪些数据的很重要一点，如果设计的不好，可能会导致缓存命中率过低，失去缓存效果。
一般对于热点数据而言，要保证命中率达到70%以上效果最佳。

缓存的穿透/雪崩问题：
是指如果缓存服务一旦宕机或全部丢失，那么有可能一瞬间所有的流量都直接打到了后端数据库上，可能会造成连锁反应，
瞬间的请求高峰极有可能导致数据库无法承载。


典型的缓存模式，一般有如下几种：

Cache Aside     读：先缓存然后db，缓存无读db写入缓存， 写：先写db后写缓存
  应用在查询数据的时候，先从缓存Cache中读取数据，如果缓存中没有，则再从数据库中读取数据，得到数据库数据后，将其也放到缓存Cache中。
  如果应用要更新某个数据，也是先去更新数据库中的数据，更新完成之后，则通过指令让缓存Cache中的数据失效。
  
  这里为什么不让更新操作在写完数据库之后，紧接着去把缓存Cache中的数据也修改了呢？
  主要是因为这样做的话，就有2个写操作的事件了，担心在并发的情况下会导致脏数据，举个例子：
    假如同时有2个请求，请求A和请求B，并发的执行。请求A是要去读数据，请求B是要去更新数据。
    初始状态缓存中是没有数据的，当请求A读到数据之后，准备往回写的时候，
    此刻，请求B正好要更新数据，更新完了数据库之后，又去把缓存更新了，那请求A再往缓存中写的就是旧数据了，属于脏数据。

那么 Cache Aside 模式就没有脏数据问题了吗？不是的，在极端情况下也可能会产生脏数据，比如：
  假如同时有2个请求，请求A和请求B，并发的执行。请求A是要去读数据，请求B是要去写数据。
  假如初始状态缓存中没有这个数据，那请求A发现缓存中没有数据，就会去数据库中读数据，读到了数据准备写回缓存中，
  就在这个时候，请求B是要去写数据的，请求B在写完数据库的数据之后，又去设置了缓存失效。
  这个时候，请求A由于在数据库中读到了之前的旧数据，开始往缓存中写数据了，此时写进入的就也是旧数据。
  那么最终就会导致，缓存中的数据与数据库的数据不一致，造成了脏数据。

不过这种概率比上面一种概率要小很多。所以整体而言 Cache Aside 模式 还是一种比较简单实用的方式。

 
Read/Write Through
  这个模式其实就是将 缓存服务 作为主要的存储，应用的所有读写请求都是直接与缓存服务打交道，而不管最后端的数据库了，
  数据库的数据由缓存服务来维护和更新。不过缓存中数据变更的时候是同步去更新数据库的，在应用的眼中只有缓存服务。

流程就相当简单了：
  应用要读数据和更新数据都直接访问缓存服务
  缓存服务同步的将数据更新到数据库
  这个模式出现脏数据的概率就比较低，但是就强依赖缓存了，对缓存服务的稳定性有较大要求，另外，增加新缓存节点时还会有初始状态空数据问题。
  
Write Behind
  这个模式就是 Read/Write Through 模式 的一个变种。
  区别就是 Read/Write Through 模式的缓存写数据库的时候是同步的，而 Write Behind 模式 的缓存操作数据库是异步的。

流程如下：
  应用要读数据和更新数据都直接访问缓存服务
  缓存服务异步的将数据更新到数据库（通过异步任务）
  这个模式的特点就是速度很快，效率会非常高，但是数据的一致性比较差，还可能会有数据的丢失情况，实现逻辑也较为复杂。

以上就是目前三种主流的缓存更新策略，另外还有Refrsh-Ahead模式等由于使用的不是很常见就不详细介绍了。





