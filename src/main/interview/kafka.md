链接：https://www.jianshu.com/p/5ad457dc0783
indexIntervalBytes可以理解为插了多少消息之后再建一个索引，由此可以看出Kafka的索引其实是稀疏索引，
    这样可以避免索引文件占用过多的内存，从而可以在内存中保存更多的索引。
    对应的就是Broker 端参数log.index.interval.bytes 值，默认4KB。

实际的通过索引查找消息过程是先通过offset找到索引所在的文件，然后通过二分法找到离目标最近的索引，再顺序遍历消息文件找到目标文件。
这波操作时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。

这就是空间和时间的互换，又经过数据结构与算法的平衡，妙啊！
    再说下rollJitterMs,这其实是个扰动值，对应的参数是log.roll.jitter.ms,
    这其实就要说到日志段的切分了，log.segment.bytes,这个参数控制着日志段文件的大小，默认是1G，
    
    即当文件存储超过1G之后就新起一个文件写入。这是以大小为维度的，还有一个参数是log.segment.ms,以【时间】为维度切分。
    那配置了这个参数之后如果有很多很多分区，然后因为这个参数是全局的，因此同一时刻需要做很多文件的切分，
    这磁盘IO就顶不住了啊，因此需要设置个rollJitterMs，来岔开它们。
怎么样有没有联想到redis缓存的过期时间？过期时间加个随机数，防止同一时刻大量缓存过期导致缓存击穿数据库。 看看知识都是通的啊！



Kafka Broker 网络通信模型
简单来说就是，Broker 中有个Acceptor(mainReactor)监听新连接的到来，
    与新连接建连之后轮询选择一个Processor(subReactor)管理这个连接。

而Processor会监听其管理的连接，当事件到达之后，读取封装成Request，并将Request放入共享请求队列中。
    然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的Processor的响应队列中，
    然后由Processor将Response返还给客户端。

每个listener只有一个Acceptor线程，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量，一个足矣。

Processor 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是num.network.threads。并且可以根据实际的业务动态增减。
还有个 IO 线程池，即KafkaRequestHandlerPool，执行真正的处理，对应的参数是num.io.threads，默认值是 8。
IO线程处理完之后会将Response放入对应的Processor中，由Processor将响应返还给客户端。

可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。
    这样的好处是什么？生产者和消费者之间解耦了，可以对生产者或者消费者做独立的变更和扩展。
    并且可以平衡两者的处理能力，例如消费不过来了，我多加些IO线程。
    如果你看过其他中间件源码，你会发现生产者-消费者模式真的是太常见了，所以面试题经常会有手写一波生产者-消费者。





https://blog.csdn.net/u013573133/article/details/48142677  
  Kafka史上最详细原理总结

http://xstarcd.github.io/wiki/Cloud/kafka_Working_Principles.html  
  kafka工作原理

https://www.cnblogs.com/likehua/p/3999538.html  
  kafka入门：简介、使用场景、设计原理、主要配置及集群搭建（转）  
  
https://blog.csdn.net/suifeng3051/article/details/48053965  
  Kafka 设计与原理详解  

https://www.cnblogs.com/huxi2b/p/6223228.html  
  Kafka消费组(consumer group)

如何做到消息不丢失  
==
* ACK 机制  
>通过 ACK 机制保证消息送达。Kafka 采用的是至少一次（At least once），消息不会丢，但是可能会重复传输  

* 发送消息   
>为了得到更好的性能，Kafka 支持在生产者一侧进行本地buffer，<br>
>也就是累积到一定的条数才发送，如果这里设置不当是会丢消息的。<br>
>生产者端设置 producer.type=async, sync，默认是 sync。<br>
>当设置为 async，会大幅提升性能，因为生产者会在本地缓冲消息，并适时批量发送。<br>
>如果对可靠性要求高，那么这里可以设置为 sync 同步发送。<br>

* 消费消息<br>
>如果更注重可靠性，则需要显示提交 Offset，也就是当所有业务都处理完成的时候，再提交Offset。<br>
>这样会导致重复消费，需要提供幂等性接口。通过增加消费组的消费者来进行水平扩展提升消费能力。<br>
>这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。<br>
>另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。<br>
<br>

为什么 Kafka 性能高？
==

* 顺序写磁盘<br>
>顺序写磁盘的性能是随机写入的性能的6000倍的提升，媲美内存随机访问的性能，磁盘不再是瓶颈点。<br>

* Page Cache<br>
>为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。<br>
>通过操作系统的Page Cache，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。<br>

* 零拷贝技术<br>
>零拷贝技术，可以有效的减少上下文切换和拷贝次数。<br>
>kafka的设计实现，涉及到很多的底层技术，为了能够把它吃透，需要花大量的时间，大量的精力。

<br><br><br><br>



Kafka一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息。换句话说，每个应用都可以读到全量的消息。
为了使得每个应用都能读到全量消息，应用需要有不同的消费组。
  比如：订单生产后，产生了一条消息==>后续  【库存】需要消费当前的消息，【积分】也需要~


![多分组](https://github.com/percyqq/start/blob/master/pic/kafka%20group.png?raw=true)

消费组与分区重平衡
可以看到，当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；
另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为重平衡（rebalance）。

重平衡是Kafka一个很重要的性质，这个性质保证了高可用和水平扩展。
不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。
而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能






