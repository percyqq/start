### 一个kafka问题参考。
kafka的问题
 ==>  上线后发现大量的消息拒绝，当时每分钟上万条的消息拒绝，我们马上op发起回滚排查。
    问题发现得益于一开始就建立了异常消息缓存到本地的处理和异常报警机制 让线上问题第一时间发现
1.2 导致的原因
1 消费缓存3天的全量数据
2 消费速度过快 qps: 1.3k
3 spring kafka client 1.3.x之前不支持@KafkaListener 单独配置group-id，服务上线版本刚好使用了1.3.x之前版本

1.3 如何解决
1 将kafka消费的group id 换回到原来的group id（升级spring kafka 版本到1.3.0并反复测试group id是否是之前已用的），
    让服务消费当前最近offset，避免全量拉取数据
2 线程池使用改用CallRun 策略实现背压，当消息处理不过来的时候反压到kafka接收暂停。
3 线程池的blockingqueue 使用 SynchronousQueue，原因是消息不要本地缓存，用其他queue无意义并且容易导致数据丢失问题。 
    另外如果使用有缓存的queue的话会在服务启动瞬间读取很多数据 导致流量突刺问题

Kafka索引设计有什么亮点？
    https://www.jianshu.com/p/5f39ad4a710d
    

https://www.jianshu.com/p/5f39ad4a710d
#Kafka索引设计解读
Kafka使用了改进版的二分查找，改的不是二分查找的内部，而且把所有索引项分为热区和冷区
    这个改进可以让查询热数据部分时，遍历的Page永远是固定的，这样能避免缺页中断。
    看到这里其实我想到了一致性hash，一致性hash相对于普通的hash不就是在node新增的时候缓存的访问固定，或者只需要迁移少部分数据。

从Kafka的索引冷热分区到MySQL InnoDB的缓冲池管理
    从上面这波冷热分区我又想到了MySQL的buffer pool管理。MySQL的将缓冲池分为了新生代和老年代。默认是37分，即老年代占3，新生代占7。
        即看作一个链表的尾部30%为老年代，前面的70%为新生代。替换了标准的LRU淘汰机制。
MySQL的缓冲池分区是为了解决预读失效和缓存污染问题。
    1、预读失效：因为会预读页，假设预读的页不会用到，那么就白白预读了，因此让预读的页插入的是老年代头部，淘汰也是从老年代尾部淘汰。不会影响新生代数据。
    2、缓存污染：在类似like全表扫描的时候，会读取很多冷数据。并且有些查询频率其实很少，因此让这些数据仅仅存在老年代，然后快速淘汰才是正确的选择，
        MySQL为了解决这种问题，仅仅分代是不够的，还设置了一个时间窗口，默认是1s，即在老年代被再次访问并且存在超过1s，才会晋升到新生代，
        这样就不会污染新生代的热数据。
#####



注意，ack的默认值就是1。这个默认值其实就是吞吐量与可靠性的一个折中方案。
    生产上我们可以根据实际情况进行调整，比如如果你要追求高吞吐量，那么就要放弃可靠性。
[
ack=1，简单来说就是，producer只要收到一个分区副本成功写入的通知就认为推送消息成功了。
    这里有一个地方需要注意，这个副本必须是leader副本。只有leader副本成功写入了，producer才会认为消息发送成功。
ack=0，简单来说就是，producer发送一次就不再发送了，不管是否发送成功。
ack=-1，简单来说就是，producer只有收到分区内所有副本的成功写入的通知才认为推送消息成功了。
]

num.partitions 参数指定了新创建的主题需要包含多少个分区。
    比如有个topic叫[订单信息]，那么可能需要多个分区 来 分发 给不同的消费者。缓解订单数据大量来，来不及消费。
    单个分区内是有序的。因此，出现了相关订单这种，可以发送到同一个分区。


==========================================================================================
kafka时间轮算法
https://mp.weixin.qq.com/s/lBJs8mQpPJGdleLqtGS-dw

Kafka 用了多层次时间轮来实现，并且是按需创建时间轮，采用任务的绝对时间来判断延期，
    并且对于每个槽(槽内存放的也是任务的双向链表)都会维护一个过期时间，利用 DelayQueue 来对每个槽的过期时间排序，
    来进行时间的推进，防止空推进的存在。
每次推进都会更新 currentTime 为当前时间戳，当然做了点微调使得 currentTime 是 tickMs 的整数倍。
    并且每次推进都会把能降级的任务重新插入降级。
可以看到这里的 DelayQueue 的元素是每个槽，而不是任务，因此数量就少很多了，
    这应该是权衡了对于槽操作的延时队列的时间复杂度与空推进的影响。
==========================================================================================



链接：https://www.jianshu.com/p/5ad457dc0783
indexIntervalBytes可以理解为插了多少消息之后再建一个索引，由此可以看出Kafka的索引其实是稀疏索引，
    这样可以避免索引文件占用过多的内存，从而可以在内存中保存更多的索引。
    对应的就是Broker 端参数log.index.interval.bytes 值，默认4KB。

实际的通过索引查找消息过程是先通过offset找到索引所在的文件，然后通过二分法找到离目标最近的索引，再顺序遍历消息文件找到目标文件。
这波操作时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。

这就是空间和时间的互换，又经过数据结构与算法的平衡，妙啊！
    再说下rollJitterMs,这其实是个扰动值，对应的参数是log.roll.jitter.ms,
    这其实就要说到日志段的切分了，log.segment.bytes,这个参数控制着日志段文件的大小，默认是1G，
    
    即当文件存储超过1G之后就新起一个文件写入。这是以大小为维度的，还有一个参数是log.segment.ms,以【时间】为维度切分。
    那配置了这个参数之后如果有很多很多分区，然后因为这个参数是全局的，因此同一时刻需要做很多文件的切分，
    这磁盘IO就顶不住了啊，因此需要设置个rollJitterMs，来岔开它们。
怎么样有没有联想到redis缓存的过期时间？过期时间加个随机数，防止同一时刻大量缓存过期导致缓存击穿数据库。 看看知识都是通的啊！



Kafka Broker 网络通信模型
简单来说就是，Broker 中有个Acceptor(mainReactor)监听新连接的到来，
    与新连接建连之后轮询选择一个Processor(subReactor)管理这个连接。

而Processor会监听其管理的连接，当事件到达之后，读取封装成Request，并将Request放入共享请求队列中。
    然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的Processor的响应队列中，
    然后由Processor将Response返还给客户端。

每个listener只有一个Acceptor线程，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量，一个足矣。

Processor 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是num.network.threads。并且可以根据实际的业务动态增减。
还有个 IO 线程池，即KafkaRequestHandlerPool，执行真正的处理，对应的参数是num.io.threads，默认值是 8。
IO线程处理完之后会将Response放入对应的Processor中，由Processor将响应返还给客户端。

可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。
    这样的好处是什么？生产者和消费者之间解耦了，可以对生产者或者消费者做独立的变更和扩展。
    并且可以平衡两者的处理能力，例如消费不过来了，我多加些IO线程。
    如果你看过其他中间件源码，你会发现生产者-消费者模式真的是太常见了，所以面试题经常会有手写一波生产者-消费者。


这也是经常被提及的一个问题。rebalance的触发条件有三种：
    1.组成员发生变更(新consumer加入组、已有consumer主动离开组或已有consumer崩溃了——这两者的区别后面会谈到)
    2订阅主题数发生变更——这当然是可能的，如果你使用了正则表达式的方式进行订阅，那么新建匹配正则表达式的topic就会触发rebalance
    3.订阅主题的分区数发生变更


https://www.cnblogs.com/huxi2b/p/6223228.html
    Kafka消费组(consumer group)

https://blog.csdn.net/u013573133/article/details/48142677  
  Kafka史上最详细原理总结

http://xstarcd.github.io/wiki/Cloud/kafka_Working_Principles.html  
  kafka工作原理

https://www.cnblogs.com/likehua/p/3999538.html  
  kafka入门：简介、使用场景、设计原理、主要配置及集群搭建（转）  
  
https://blog.csdn.net/suifeng3051/article/details/48053965  
  Kafka 设计与原理详解  

https://www.cnblogs.com/huxi2b/p/6223228.html  
  Kafka消费组(consumer group)

如何做到消息不丢失  
==
* ACK 机制  
>通过 ACK 机制保证消息送达。Kafka 采用的是至少一次（At least once），消息不会丢，但是可能会重复传输  

* 发送消息   
>为了得到更好的性能，Kafka 支持在生产者一侧进行本地buffer，<br>
>也就是累积到一定的条数才发送，如果这里设置不当是会丢消息的。<br>
>生产者端设置 producer.type=async, sync，默认是 sync。<br>
>当设置为 async，会大幅提升性能，因为生产者会在本地缓冲消息，并适时批量发送。<br>
>如果对可靠性要求高，那么这里可以设置为 sync 同步发送。<br>

* 消费消息<br>
>如果更注重可靠性，则需要显示提交 Offset，也就是当所有业务都处理完成的时候，再提交Offset。<br>
>这样会导致重复消费，需要提供幂等性接口。通过增加消费组的消费者来进行水平扩展提升消费能力。<br>
>这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。<br>
>另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。<br>
<br>

== https://www.jianshu.com/p/818826aa4e45
为什么 Kafka 性能高？

架构层面
   1.ISR-可用性和一致性的动态平衡
    Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。
        从一这点来讲，Kafka的数据复制方案接近于Master-Slave方案。
        不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。
    ISR，也即In-sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，
        包含了所有与之同步的Replica（包含Leader自己）。
        每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。
    这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，
        它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。
        每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。
    
   2.利用partiton并行处理
    kafka每个Topic都包含一个或多个Partition，不同Partition可位于不同节点。
    同时Partition在物理上对应一个本地文件夹，每个Partition包含一个或多个Segment，
        每个Segment包含一个数据文件和一个与之对应的索引文件。
        在逻辑上，可以把一个Partition当作一个非常长的数组，可通过这个“数组”的索引（offset）去访问其数据。
    一方面，由于不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。
    另一方面，由于Partition在物理上对应一个文件夹，即使多个Partition位于同一个节点，
    也可通过配置让同一节点上的不同Partition置于不同的disk drive上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

具体实现层面       
* 顺序写磁盘 
>顺序写磁盘的性能是随机写入的性能的6000倍的提升，媲美内存随机访问的性能，磁盘不再是瓶颈点。<br>
    Kafka的整个设计中，Partition相当于一个非常长的数组，而Broker接收到的所有消息顺序写入这个大数组中。
    同时Consumer通过Offset顺序消费这些数据，并且不删除已经消费的数据，从而避免了随机写磁盘的过程。
    由于磁盘有限，不可能保存所有数据，实际上作为消息系统Kafka也没必要保存所有数据，需要删除旧的数据。
    而这个删除过程，并非通过使用“读-写”模式去修改文件，而是将Partition分为多个Segment，每个Segment对应一个物理文件，
    通过删除整个文件的方式去删除Partition内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。

* Page Cache 
>为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。<br>
>通过操作系统的Page Cache，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。<br>
使用Page Cache的好处如下：
    1.I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能；
    2.I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间；
    3.充分利用所有空闲内存（非JVM内存）。如果使用应用层Cache（即JVM堆内存），会增加GC负担；
    4.读操作可直接在Page Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过Page Cache）交换数据；
    5.如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用。
    

* 零拷贝技术 
>零拷贝技术，可以有效的减少上下文切换和拷贝次数。<br>
>kafka的设计实现，涉及到很多的底层技术，为了能够把它吃透，需要花大量的时间，大量的精力。
    Kafka中存在大量的网络数据持久化到磁盘（Producer到Broker）和磁盘文件通过网络发送（Broker到Consumer）的过程。
    这一过程的性能直接影响Kafka的整体吞吐量。>
   Linux 2.4+内核通过sendfile系统调用，提供了零拷贝。
    数据通过DMA拷贝到内核态Buffer后，直接通过DMA拷贝到NIC Buffer，无需CPU拷贝。
    除了减少数据拷贝外，因为整个读文件-网络发送由一个sendfile调用完成，整个过程只有两次上下文切换，因此大大提高了性能。
    注： transferTo和transferFrom并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，
       如果操作系统提供sendfile这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，
       否则并不能通过这两个方法本身实现零拷贝。

* 支持多Disk Drive
    Broker的log.dirs配置项，允许配置多个文件夹。如果机器上有多个Disk Drive，可将不同的Disk挂载到不同的目录，
        然后将这些目录都配置到log.dirs里。
        Kafka会尽可能将不同的Partition分配到不同的目录，也即不同的Disk上，从而充分利用了多Disk的优势。

减少网络开销
    1.批处理
        将同步Producer和异步Producer结合,send方法并非立即将消息发送出去，
            而是通过batch.size和linger.ms控制实际发送频率，从而实现批量发送。
    2.数据压缩，降低网络负载
    3.高效的序列化方式



Kafka一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息。换句话说，每个应用都可以读到全量的消息。
为了使得每个应用都能读到全量消息，应用需要有不同的消费组。
  比如：订单生产后，产生了一条消息==>后续  【库存】需要消费当前的消息，【积分】也需要~


![多分组](https://github.com/percyqq/start/blob/master/pic/kafka%20group.png?raw=true)

消费组与分区重平衡
可以看到，当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；
另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为重平衡（rebalance）。

重平衡是Kafka一个很重要的性质，这个性质保证了高可用和水平扩展。
不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。
而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能






