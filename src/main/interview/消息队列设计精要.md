https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/why-mq.md  
  为什么使用消息队列？  
  消息队列有什么优点和缺点？  
  Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？  
https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md      
  如何保证消息队列的高可用？  

https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md  
  如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？  
https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/mq-time-delay-and-expired-failure.md  
  如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？    
  
https://tech.meituan.com/2016/07/01/mq-design.html


1.解耦
解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。
  换句话说，基于消息的模型，关心的是“通知”，而非“处理”。

2.最终一致性
最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。当然有个时间限制，理论上越快越好，但实际上在各种异常的情况下，
  可能会有一定延迟达到最终一致状态，但最后两个系统的状态是一样的。 业界有一些为“最终一致性”而生的消息队列，如Notify（阿里）、QMQ（去哪儿）等，
  其设计初衷，就是为了交易系统中的高可靠通知。 

3.广播
消息队列的基本功能之一是进行广播。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，
  至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。

4.错峰与流控
试想上下游对于事情的处理能力是不同的。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，
  再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。
  由于成本的考虑，我们不能奢求数据库的机器数量追上前端。 
这种问题同样存在于系统和系统之间，如短信系统可能由于短板效应，速度卡在网关上（每秒几百次请求），跟前端的并发量不是一个数量级。
但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。
如果没有消息队列，两个系统之间通过协商、滑动窗口等复杂的方案也不是说不能实现。
但系统复杂性指数级增长，势必在上游或者下游做存储，并且要处理定时、拥塞等一系列问题。
而且每当有处理能力有差距的时候，都需要单独开发一套逻辑来维护这套逻辑。
所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。

总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。 
对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。 
支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景，而且相对于笨重的分布式事务，可能是更优的处理方式。 
当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。 
如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。



===> 设计实现一个消息队列

a.所谓消息队列，无外乎两次RPC加一次转储，当然需要消费端最终做消费确认的情况是三次RPC。
  既然是RPC，就必然牵扯出一系列话题，什么负载均衡啊、服务发现啊、通信协议啊、序列化协议啊，等等。
  在这一块，我的强烈建议是不要重复造轮子。利用公司现有的RPC框架：Thrift也好，Dubbo也好，或者是其他自定义的框架也好。
  因为消息队列的RPC，和普通的RPC没有本质区别。
  当然了，自主利用Memchached或者Redis协议重新写一套RPC框架并非不可（如MetaQ使用了自己封装的Gecko NIO框架，卡夫卡也用了类似的协议）。
  但实现成本和难度无疑倍增。排除对效率的极端要求，都可以使用现成的RPC框架。 简单来讲，服务端提供两个RPC服务，一个用来接收消息，一个用来确认消息收到。
  并且做到不管哪个server收到消息和确认消息，结果一致即可。
  当然这中间可能还涉及跨IDC的服务的问题。这里和RPC的原则是一致的，尽量优先选择本机房投递。
  
  你可能会问，如果producer和consumer本身就在两个机房了，怎么办？首先，broker必须保证感知的到所有consumer的存在。
  其次，producer尽量选择就近的机房就好了。


b.高可用
其实所有的高可用，是依赖于RPC和存储的高可用来做的。先来看RPC的高可用，美团的基于MTThrift的RPC框架，阿里的Dubbo等，
  其本身就具有服务自动发现，负载均衡等功能。
  而消息队列的高可用，只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的，这样就把消息队列的可用性，
  转交给RPC框架来处理了。
  那么怎么保证幂等呢？最简单的方式莫过于共享存储。broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的。
  就算有单点故障，其他节点可以立刻顶上。另外failover可以依赖定时任务的补偿，这是消息队列本身天然就可以支持的功能。

c.服务端承载消息堆积的能力
  消息到达服务端如果不经过任何处理就到接收者了，broker就失去了它的意义。为了满足我们错峰/流控/最终可达等一系列需求，把消息存储下来，
    然后选择时机投递就显得是顺理成章的了。 只是这个存储可以做成很多方式。比如存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里等等。
    但归结起来，主要有持久化和非持久化两种。 
    持久化的形式能更大程度地保证消息的可靠性（如断电等不可抗外力），并且理论上能承载更大限度的消息堆积（外存的空间远大于内存）。 
    但并不是每种消息都需要持久化存储。很多消息对于投递性能的要求大于可靠性的要求，且数量极大（如日志）。
    这时候，消息不落地直接暂存内存，尝试几次failover，最终投递出去也未尝不可。 
    市面上的消息队列普遍两种形式都支持。当然具体的场景还要具体结合公司的业务来看。
    
d.存储子系统的选择
  我们来看看如果需要数据落地的情况下各种存储子系统的选择。理论上，从速度来看，文件系统>分布式KV（持久化）>分布式文件系统>数据库，而可靠性却截然相反。
  还是要从支持的业务场景出发作出最合理的选择，如果你们的消息队列是用来支持支付/交易等对可靠性要求非常高，但对性能和量的要求没有这么高，
  而且没有时间精力专门做文件存储系统的研究，DB是最好的选择。 
  但是DB受制于IOPS，如果要求单broker 5位数以上的QPS性能，基于文件的存储是比较好的解决方案。
  整体上可以采用数据文件+索引文件的方式处理，具体这块的设计比较复杂，可以参考下篇的存储子系统设计。 
  分布式KV（如MongoDB，HBase）等，或者持久化的Redis，由于其编程接口较友好，性能也比较可观，如果在可靠性要求不是那么高的场景，也不失为一个不错的选择。

e.消费关系解析
  现在我们的消息队列初步具备了转储消息的能力。下面一个重要的事情就是解析发送接收关系，进行正确的消息投递了。 
  市面上的消息队列定义了一堆让人晕头转向的名词，如JMS 规范中的Topic/Queue，Kafka里面的Topic/Partition/ConsumerGroup，RabbitMQ里面的Exchange等等。
  抛开现象看本质，无外乎是单播与广播的区别。
    所谓单播，就是点到点；
    而广播，是一点对多点。
   当然，对于互联网的大部分应用来说，组间广播、组内单播是最常见的情形。 
    消息需要通知到多个业务集群，而一个业务集群内有很多台机器，只要一台机器消费这个消息就可以了。 
    当然这不是绝对的，很多时候组内的广播也是有适用场景的，如本地缓存的更新等等。
    另外，消费关系除了组内组间，可能会有多级树状关系。这种情况太过于复杂，一般不列入考虑范围。
    所以，一般比较通用的设计是支持组间广播，不同的组注册不同的订阅。
    组内的不同机器，如果注册一个相同的ID，则单播；
    如果注册不同的ID(如IP地址+端口)，则广播。 
    至于广播关系的维护，一般由于消息队列本身都是集群，所以都维护在公共存储上，如config server、zookeeper等。维护广播关系所要做的事情基本是一致的:
1.发送关系的维护。
2.发送关系变更时的通知。


==============================================
队列高级特性设计
A.可靠投递（最终一致性）
  这是个激动人心的话题，完全不丢消息，究竟可不可能？答案是，完全可能，前提是消息可能会重复，并且，在异常情况下，要接受消息的延迟。 
  方案说简单也简单，就是每当要发生不可靠的事情（RPC等）之前，先将消息落地，然后发送。
  当失败或者不知道成功失败（比如超时）时，消息状态是待发送，定时任务不停轮询所有待发送消息，最终一定可以送达。 具体来说：

    1.producer往broker发送消息之前，需要做一次落地。
    2.请求到server后，server确保数据落地后再告诉客户端发送成功。
    3.支持广播的消息队列需要对每个待发送的endpoint，持久化一个发送状态，直到所有endpoint状态都OK才可删除消息。
    
  对于各种不确定（超时、down机、消息没有送达、送达后数据没落地、数据落地了回复没收到），其实对于发送方来说，都是一件事情，就是消息没有送达。
  重推消息所面临的问题就是消息重复。重复和丢失就像两个噩梦，你必须要面对一个。好在消息重复还有处理的机会，消息丢失再想找回就难了。
  Anyway，作为一个成熟的消息队列，应该尽量在各个环节减少重复投递的可能性，不能因为重复有解决方案就放纵的乱投递。 
  最后说一句，不是所有的系统都要求最终一致性或者可靠投递，比如一个论坛系统、一个招聘系统。
    一个重复的简历或话题被发布，可能比丢失了一个发布显得更让用户无法接受。不断重复一句话，任何基础组件要服务于业务场景。

B.消费确认
  当broker把消息投递给消费者后，消费者可以立即响应我收到了这个消息。但收到了这个消息只是第一步，我能不能处理这个消息却不一定。
  或许因为消费能力的问题，系统的负荷已经不能处理这个消息；或者是刚才状态机里面提到的消息不是我想要接收的消息，主动要求重发。 
  把消息的送达和消息的处理分开，这样才真正的实现了消息队列的本质-解耦。
  所以，允许消费者主动进行消费确认是必要的。当然，对于没有特殊逻辑的消息，默认Auto Ack也是可以的，但一定要允许消费方主动ack。
  对于正确消费ack的，没什么特殊的。
  
  但是对于reject和error，需要特别说明。reject这件事情，往往业务方是无法感知到的，系统的流量和健康状况的评估，以及处理能力的评估是一件非常复杂的事情。
  举个极端的例子，收到一个消息开始build索引，可能这个消息要处理半个小时，但消息量却是非常的小。
  所以reject这块建议做成滑动窗口/线程池类似的模型来控制， 消费能力不匹配的时候，直接拒绝，过一段时间重发，减少业务的负担。 
  但业务出错这件事情是只有业务方自己知道的，就像上文提到的状态机等等。这时应该允许业务方主动ack error，并可以与broker约定下次投递的时间。

C.重复消息和顺序消息
  1.允许消息丢失。
  2.从发送方到服务方到接受者都是单点单线程。

  所以绝对的顺序消息基本上是不能实现的，当然在METAQ/Kafka等pull模型的消息队列中，单线程生产/消费，排除消息丢失，也是一种顺序消息的解决方案。 +
    一般来讲，一个主流消息队列的设计范式里，应该是不丢消息的前提下，尽量减少重复消息，不保证消息的投递顺序。 谈到重复消息，主要是两个话题：
      1.如何鉴别消息重复，并幂等的处理重复消息。
          每一个消息应该有它的唯一身份。不管是业务方自定义的，还是根据IP/PID/时间戳生成的MessageId，如果有地方记录这个MessageId，
          消息到来是能够进行比对就 能完成重复的鉴定。数据库的唯一键/bloom filter/分布式KV中的key，都是不错的选择。
          由于消息不能被永久存储，所以理论上都存在消息从持久化存储移除的瞬间上游还在投递的可能（上游因种种原因投递失败，不停重试，都到了下游清理消息的时间）。
          这种事情都是异常情况下才会发生的，毕竟是小众情况。两分钟消息都还没送达，多送一次又能怎样呢？
          幂等的处理消息是一门艺术，因为种种原因重复消息或者错乱的消息还是来到了，说两种通用的解决方案： 1. 版本号。 2. 状态机。
      2.一个消息队列如何尽量减少重复消息的投递。


D.事务
  持久性是事务的一个特性，然而只满足持久性却不一定能满足事务的特性。还是拿扣钱/加钱的例子讲。满足事务的一致性特征，则必须要么都不进行，要么都能成功。
  解决方案从大方向上有两种：
    1.两阶段提交，分布式事务。
    2.本地事务，本地落地，补偿发送。

  分布式事务存在的最大问题是成本太高，两阶段提交协议，对于仲裁down机或者单点故障，几乎是一个无解的黑洞。
  对于交易密集型或者I/O密集型的应用，没有办法承受这么高的网络延迟，系统复杂性。 
  并且成熟的分布式事务一定构建与比较靠谱的商用DB和商用中间件上，成本也太高。 
   
   那如何使用本地事务解决分布式事务的问题呢？以本地和业务在一个数据库实例中建表为例子，与扣钱的业务操作同一个事务里，将消息插入本地数据库。
      如果消息入库失败，则业务回滚；如果消息入库成功，事务提交。 然后发送消息（注意这里可以实时发送，不需要等定时任务检出，以提高消息实时性）。
      以后的问题就是前文的最终一致性问题所提到的了，只要消息没有发送成功，就一直靠定时任务重试。 
      
      这里有一个关键的点，本地事务做的，是业务落地和消息落地的事务，而不是业务落地和RPC成功的事务。
      
      这里很多人容易混淆，如果是后者，无疑是事务嵌套RPC，是大忌，会有长事务死锁等各种风险。 
      而消息只要成功落地，很大程度上就没有丢失的风险（磁盘物理损坏除外）。
      而消息只要投递到服务端确认后本地才做删除，就完成了producer->broker的可靠投递，并且当消息存储异常时，业务也是可以回滚的。 
      本地事务存在两个最大的使用障碍：
        1.配置较为复杂，“绑架”业务方，必须本地数据库实例提供一个库表。
        2.对于消息延迟高敏感的业务不适用。

============================
性能相关
  异步/同步
  首先澄清一个概念，异步，同步和oneway是三件事。
  
 https://github.com/shishan100/Java-Interview-Advanced/raw/master/images/rabbitmq-message-lose.png 
  
  

谈到批量就不得不提生产者消费者模型。但生产者消费者模型中最大的痛点是：消费者到底应该何时进行消费。大处着眼来看，消费动作都是事件驱动的。主要事件包括：
  1.攒够了一定数量。
  2.到达了一定时间。
  3.队列里有新的数据到来。


push还是pull
  慢消费
    慢消费无疑是push模型最大的致命伤，穿成流水线来看，如果消费者的速度比发送者的速度慢很多，势必造成消息在broker的堆积。
    假设这些消息都是有用的无法丢弃的，消息就要一直在broker端保存。
    当然这还不是最致命的，最致命的是broker给consumer推送一堆consumer无法处理的消息，consumer不是reject就是error，然后来回踢皮球。 
    
    反观pull模式，consumer可以按需消费，不用担心自己处理不了的消息来骚扰自己，而broker堆积消息也会相对简单，无需记录每一个要发送消息的状态，
    只需要维护所有消息的队列和偏移量就可以了。所以对于建立索引等慢消费，消息量有限且到来的速度不均匀的情况，pull模式比较合适。

在阿里的RocketMq里，有一种优化的做法-长轮询，来平衡推拉模型各自的缺点。
  基本思路是:消费者如果尝试拉取失败，不是直接return,而是把连接挂在那里wait,服务端如果有新的消息到来，把连接notify起来，这也是不错的思路。
  但海量的长连接block对系统的开销还是不容小觑的，还是要合理的评估时间间隔，给wait加一个时间上限比较好~


顺序消息
  如果push模式的消息队列，支持分区，单分区只支持一个消费者消费，并且消费者只有确认一个消息消费后才能push送另外一个消息，
  还要发送者保证全局顺序唯一，听起来也能做顺序消息，但成本太高了，尤其是必须每个消息消费确认后才能发下一条消息，
  这对于本身堆积能力和慢消费就是瓶颈的push模式的消息队列，简直是一场灾难。 
  
  反观pull模式，如果想做到全局顺序消息，就相对容易很多：
    1.producer对应partition，并且单线程。
    2.consumer对应partition，消费确认（或批量确认），继续消费即可。







