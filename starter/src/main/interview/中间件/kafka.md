### 一个kafka问题参考。

增加主题分区。当增加主题分区后，在某段“不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，
因此在 Consumer 感知到新分区前，Producer 发送的这些消息就全部“丢失”了，或者说 Consumer 无法读取到这些消息。
严格来说这是 Kafka 设计上的一个小缺陷，你有什么解决的办法吗？      
    [消费者配置的是 ： auto.offset.reset=latest
    新增分区之后，producer先感知并发送数据，消费者后感知，消费者的offset会定位到新分区的最后一条消息]

A. 重复消费问题
重复消费问题可以说是 MQ 中普遍存在的问题， 不管你用哪种 MQ 都无法避免。有哪些场景会出现重复的消息呢？
    1.消息生产者产生了重复的消息；
    2.Kafka 和 RocketMQ 的 offset 被回调了；
    3.消息消费者确认失败；
    4.消息消费者确认时超时；
    5.业务系统主动发起重试。
不管是由于生产者产生的重复消息，还是由于消费者导致的重复消息，我们都可以在消费者中解决这个问题。
    这就要求消费者在做业务处理时，要做幂等设计。在这里我推荐增加一张消费消息表，来解决 MQ的这类问题。
    消费消息表中，使用 messageId 做唯一索引。在处理业务逻辑之前，先根据 messageId 查询一下该消息有没有处理过。
    如果已经处理过了则直接返回成功，如果没有处理过，则继续做业务处理。

B. 数据一致性问题
我们都知道数据一致性分为：强一致性、弱一致性、最终一致性。
而 MQ 为了性能考虑使用的是最终一致性，那么必定会出现数据不一致的问题。这类问题大概率是因为消费者读取消息后，业务逻辑处理失败导致的。
    这时候可以增加重试机制。重试分为同步重试和异步重试。
    1.有些消息量比较小的业务场景，可以采用同步重试。在消费消息时如果处理失败，立刻重试 3-5 次，如果还是失败则写入到记录表中。
    2.但如果消息量比较大，则不建议使用这种方式。因为如果出现网络异常，可能会导致大量的消息不断重试，影响消息读取速度造成消息堆积。
    消息量比较大的业务场景，建议采用异步重试。在消费者处理失败之后，立刻写入重试表，有个 job(如采用xxljob) 专门定时重试。
    还有一种做法：如果消费失败，自己给同一个 topic 发一条消息。在后面的某个时间点，自己又会消费到那条消息，起到了重试的效果。
    如果对消息顺序要求不高的场景，可以使用这种方式。

C. 消息丢失问题
    1.生产者产生消息时，由于网络原因发送到 MQ 失败了；
    2.MQ 服务器持久化，存储磁盘时出现异常；
    3.Kafka和RocketMQ 的 offset 被回调时，略过了很多消息；
    4.消费者刚读取消息，已经 ACK 确认，但业务还没处理完，服务就被重启了。
生产者、MQ 服务器、消费者都有可能会导致消息丢失的问题。为了解决这个问题，我们可以增加一张消息发送表。
    当生产者发完消息之后，会往该表中写入一条数据，状态 status 标记为待确认；
    如果消费者读取消息之后，调用生产者的 API 更新该消息的status为已确认；
    有个job(xxljob) 每隔一段时间检查一次消息发送表，如果5分钟（这个时间可以根据实际情况来定）后还有状态是待确认的消息，则认为该消息已经丢失了，重新发条消息。


leader 提供对外的读写，follower不提供。

#生产者丢失消息#
    先介绍一下生产者发送消息的一般流程（部分流程与具体配置项强相关，这里先忽略）：
[   1. 生产者是与leader直接交互，所以先从集群获取topic对应分区的leader元数据；
    2. 获取到leader分区元数据后直接将消息发给过去；
    3. Kafka Broker对应的leader分区收到消息后写入文件持久化；
    4. Follower拉取Leader消息与Leader的数据保持一致；
    5. Follower消息拉取完毕需要给Leader回复ACK确认消息；
    6. Kafka Leader和Follower分区同步完，Leader分区会给生产者回复ACK确认消息。]

生产者采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘。消息写入Leader后，Follower是主动与Leader进行同步。
Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。
Kafka通过配置request.required.acks属性来确认消息的生产：
[   0表示不进行消息接收是否成功的确认；不能保证消息是否发送成功，生成环境基本不会用。
    1表示当Leader接收成功时确认；只要Leader存活就可以保证不丢失，保证了吞吐量。
    -1或者all表示Leader和Follower都接收成功时确认；可以最大限度保证消息不丢失，但是吞吐量低。
    kafka producer 的参数acks 的默认值为1，所以默认的producer级别是at least once，并不能exactly once。]

敲黑板了，这里可能会丢消息的！
[   如果acks配置为0，发生网络抖动消息丢了，生产者不校验ACK自然就不知道丢了。
    如果acks配置为1保证leader不丢，但是如果leader挂了，恰好选了一个没有ACK的follower，那也丢了。
    all：保证leader和follower不丢，但是如果网络拥塞，没有收到ACK，会有重复发的问题。]

#Kafka Broker丢失消息#
操作系统本身有一层缓存，叫做 Page Cache，当往磁盘文件写入的时候，系统会先将数据流写入缓存中，至于什么时候将缓存的数据写入文件中是由操作系统自行决定。
Kafka提供了一个参数 producer.type 来控制是不是主动flush，如果Kafka写入到mmap之后就立即 flush 然后再返回 Producer 叫同步 (sync)；
写入mmap之后立即返回 Producer 不调用 flush 叫异步 (async)。
敲黑板了，这里可能会丢消息的！
    Kafka通过多分区多副本机制 已经能最大限度保证数据不会丢失，如果数据已经写入系统cache 中但是还没来得及刷入磁盘，此时突然机器宕机或者掉电那就丢了，当然这种情况很极端。

#消费者丢失消息#
   //消费者通过pull模式主动的去 kafka 集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader分区去拉取。
   多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id。
   同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会出现多个消费者消费同一分区的数据。

消费者消费的进度通过offset保存在kafka集群的__consumer_offsets这个topic中。

消费消息的时候主要分为两个阶段：
    1、标识消息已被消费，commit offset坐标；
    2、处理消息。
敲黑板了，这里可能会丢消息的！
    场景一：先commit再处理消息。如果在处理消息的时候异常了，但是offset 已经提交了，这条消息对于该消费者来说就是丢失了，再也不会消费到了。
    场景二：先处理消息再commit。如果在commit之前发生异常，下次还会消费到该消息，重复消费的问题可以通过业务保证消息幂等性来解决。



D. 消息顺序问题
    1.Kafka 同一个 partition 中能保证顺序，但是不同的 partition 无法保证顺序；
    2.RabbitMQ的同一个queue能够保证顺序，但是如果多个消费者同一个queue 也会有顺序问题。
    3.如果消费者使用多线程消费消息，也无法保证顺序。
    4.如果消费消息时同一个订单的多条消息中，中间的一条消息出现异常情况，顺序将会被打乱。
    5.还有如果生产者发送到 MQ中的路由规则，跟消费者不一样，也无法保证顺序。
解决这类问题之前，我们需要先确认：消费者是否真的需要知道中间状态，只知道最终状态行不行？
    比如收到了消息，先调用业务方api回查，再处理，而不是依赖消息体，比如人家只发 orderId，你需要的数据通过接口去捞。

E. 消息堆积
    这个要看消息是否需要保证顺序。如果不需要保证顺序，可以读取消息之后用多线程处理业务逻辑。
    但是线程池的核心线程数和最大线程数需要合理配置，不然可能会浪费系统资源。
    如果需要保证顺序，可以读取消息之后将消息按照一定的规则分发到多个队列中，然后在队列中用单线程处理。






消息堆积是消费滞后(Lag)的一种

多个topic 的多个分区，一个消费者，
导致某一个lag积累


ConsumerNetworkClient
参考  kafka reactor.jpg
（1）Acceptor：1个接收线程，负责监听新的连接请求，同时注册OP_ACCEPT 事件，将新的连接按照"round robin"方式交给对应的 Processor 线程处理；
（2）Processor：N个处理器线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事件，
        N 的大小由“num.networker.threads”决定；
（3）KafkaRequestHandler：M个请求处理线程，包含在线程池—KafkaRequestHandlerPool内部，
        从RequestChannel的全局请求队列—requestQueue中获取请求数据并交给KafkaApis处理，M的大小由“num.io.threads”决定；
（4）RequestChannel：其为Kafka服务端的请求通道，该数据结构中包含了一个全局的请求队列 requestQueue和多个与Processor处理器相对应的响应队列responseQueue，
        提供给Processor与请求处理线程KafkaRequestHandler和KafkaApis交换数据的地方。
（5）NetworkClient：其底层是对 Java NIO 进行相应的封装，位于Kafka的网络接口层。Kafka消息生产者对象—KafkaProducer的send方法主要调用NetworkClient完成消息发送；
（6）SocketServer：其是一个NIO的服务，它同时启动一个Acceptor接收线程和多个Processor处理器线程。提供了一种典型的Reactor多线程模式，将接收客户端请求和处理请求相分离；
（7）KafkaServer：代表了一个Kafka Broker的实例；其startup方法为实例启动的入口；
（8）KafkaApis：Kafka的业务逻辑处理Api，负责处理不同类型的请求；比如“发送消息”、“获取消息偏移量—offset”和“处理心跳请求”等；



kafka的问题
 ==>  上线后发现大量的消息拒绝，当时每分钟上万条的消息拒绝，我们马上op发起回滚排查。
    问题发现得益于一开始就建立了异常消息缓存到本地的处理和异常报警机制 让线上问题第一时间发现
1.2 导致的原因
1 消费缓存3天的全量数据
2 消费速度过快 qps: 1.3k
3 spring kafka client 1.3.x之前不支持@KafkaListener 单独配置group-id，服务上线版本刚好使用了1.3.x之前版本

1.3 如何解决
1 将kafka消费的group id 换回到原来的group id（升级spring kafka 版本到1.3.0并反复测试group id是否是之前已用的），
    让服务消费当前最近offset，避免全量拉取数据
2 线程池使用改用CallRun 策略实现背压，当消息处理不过来的时候反压到kafka接收暂停。
3 线程池的blockingqueue 使用 SynchronousQueue，原因是消息不要本地缓存，用其他queue无意义并且容易导致数据丢失问题。 
    另外如果使用有缓存的queue的话会在服务启动瞬间读取很多数据 导致流量突刺问题

Kafka索引设计有什么亮点？
    https://www.jianshu.com/p/5f39ad4a710d
    

https://www.jianshu.com/p/5f39ad4a710d
#Kafka索引设计解读
Kafka使用了改进版的二分查找，改的不是二分查找的内部，而且把所有索引项分为热区和冷区
    这个改进可以让查询热数据部分时，遍历的Page永远是固定的，这样能避免缺页中断。
    看到这里其实我想到了一致性hash，一致性hash相对于普通的hash不就是在node新增的时候缓存的访问固定，或者只需要迁移少部分数据。

从Kafka的索引冷热分区到MySQL InnoDB的缓冲池管理
    从上面这波冷热分区我又想到了MySQL的buffer pool管理。MySQL的将缓冲池分为了新生代和老年代。默认是37分，即老年代占3，新生代占7。
        即看作一个链表的尾部30%为老年代，前面的70%为新生代。替换了标准的LRU淘汰机制。
MySQL的缓冲池分区是为了解决预读失效和缓存污染问题。
    1、预读失效：因为会预读页，假设预读的页不会用到，那么就白白预读了，因此让预读的页插入的是老年代头部，淘汰也是从老年代尾部淘汰。不会影响新生代数据。
    2、缓存污染：在类似like全表扫描的时候，会读取很多冷数据。并且有些查询频率其实很少，因此让这些数据仅仅存在老年代，然后快速淘汰才是正确的选择，
        MySQL为了解决这种问题，仅仅分代是不够的，还设置了一个时间窗口，默认是1s，即在老年代被再次访问并且存在超过1s，才会晋升到新生代，
        这样就不会污染新生代的热数据。
#####



注意，ack的默认值就是1。这个默认值其实就是吞吐量与可靠性的一个折中方案。
    生产上我们可以根据实际情况进行调整，比如如果你要追求高吞吐量，那么就要放弃可靠性。
[
ack=1，简单来说就是，producer只要收到一个分区副本成功写入的通知就认为推送消息成功了。
    这里有一个地方需要注意，这个副本必须是leader副本。只有leader副本成功写入了，producer才会认为消息发送成功。
ack=0，简单来说就是，producer发送一次就不再发送了，不管是否发送成功。
ack=-1，简单来说就是，producer只有收到分区内所有副本的成功写入的通知才认为推送消息成功了。
]

num.partitions 参数指定了新创建的主题需要包含多少个分区。
    比如有个topic叫[订单信息]，那么可能需要多个分区 来 分发 给不同的消费者。缓解订单数据大量来，来不及消费。
    单个分区内是有序的。因此，出现了相关订单这种，可以发送到同一个分区。


==========================================================================================
kafka时间轮算法
https://mp.weixin.qq.com/s/lBJs8mQpPJGdleLqtGS-dw

Kafka 用了多层次时间轮来实现，并且是按需创建时间轮，采用任务的绝对时间来判断延期，
    并且对于每个槽(槽内存放的也是任务的双向链表)都会维护一个过期时间，利用 DelayQueue 来对每个槽的过期时间排序，
    来进行时间的推进，防止空推进的存在。
每次推进都会更新 currentTime 为当前时间戳，当然做了点微调使得 currentTime 是 tickMs 的整数倍。
    并且每次推进都会把能降级的任务重新插入降级。
可以看到这里的 DelayQueue 的元素是每个槽，而不是任务，因此数量就少很多了，
    这应该是权衡了对于槽操作的延时队列的时间复杂度与空推进的影响。
==========================================================================================



链接：https://www.jianshu.com/p/5ad457dc0783
indexIntervalBytes可以理解为插了多少消息之后再建一个索引，由此可以看出Kafka的索引其实是稀疏索引，
    这样可以避免索引文件占用过多的内存，从而可以在内存中保存更多的索引。
    对应的就是Broker 端参数log.index.interval.bytes 值，默认4KB。

实际的通过索引查找消息过程是先通过offset找到索引所在的文件，然后通过二分法找到离目标最近的索引，再顺序遍历消息文件找到目标文件。
这波操作时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。

这就是空间和时间的互换，又经过数据结构与算法的平衡，妙啊！
    再说下rollJitterMs,这其实是个扰动值，对应的参数是log.roll.jitter.ms,
    这其实就要说到日志段的切分了，log.segment.bytes,这个参数控制着日志段文件的大小，默认是1G，
    
    即当文件存储超过1G之后就新起一个文件写入。这是以大小为维度的，还有一个参数是log.segment.ms,以【时间】为维度切分。
    那配置了这个参数之后如果有很多很多分区，然后因为这个参数是全局的，因此同一时刻需要做很多文件的切分，
    这磁盘IO就顶不住了啊，因此需要设置个rollJitterMs，来岔开它们。
怎么样有没有联想到redis缓存的过期时间？过期时间加个随机数，防止同一时刻大量缓存过期导致缓存击穿数据库。 看看知识都是通的啊！



Kafka Broker 网络通信模型
简单来说就是，Broker 中有个Acceptor(mainReactor)监听新连接的到来，
    与新连接建连之后轮询选择一个Processor(subReactor)管理这个连接。

而Processor会监听其管理的连接，当事件到达之后，读取封装成Request，并将Request放入共享请求队列中。
    然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的Processor的响应队列中，
    然后由Processor将Response返还给客户端。

每个listener只有一个Acceptor线程，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量，一个足矣。

Processor 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是num.network.threads。并且可以根据实际的业务动态增减。
还有个 IO 线程池，即KafkaRequestHandlerPool，执行真正的处理，对应的参数是num.io.threads，默认值是 8。
IO线程处理完之后会将Response放入对应的Processor中，由Processor将响应返还给客户端。

可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。
    这样的好处是什么？生产者和消费者之间解耦了，可以对生产者或者消费者做独立的变更和扩展。
    并且可以平衡两者的处理能力，例如消费不过来了，我多加些IO线程。
    如果你看过其他中间件源码，你会发现生产者-消费者模式真的是太常见了，所以面试题经常会有手写一波生产者-消费者。


这也是经常被提及的一个问题。rebalance的触发条件有三种：
    1.组成员发生变更(新consumer加入组、已有consumer主动离开组或已有consumer崩溃了——这两者的区别后面会谈到)
    2订阅主题数发生变更——这当然是可能的，如果你使用了正则表达式的方式进行订阅，那么新建匹配正则表达式的topic就会触发rebalance
    3.订阅主题的分区数发生变更


https://www.cnblogs.com/huxi2b/p/6223228.html
    Kafka消费组(consumer group)

https://blog.csdn.net/u013573133/article/details/48142677  
  Kafka史上最详细原理总结

http://xstarcd.github.io/wiki/Cloud/kafka_Working_Principles.html  
  kafka工作原理

https://www.cnblogs.com/likehua/p/3999538.html  
  kafka入门：简介、使用场景、设计原理、主要配置及集群搭建（转）  
  
https://blog.csdn.net/suifeng3051/article/details/48053965  
  Kafka 设计与原理详解  

https://www.cnblogs.com/huxi2b/p/6223228.html  
  Kafka消费组(consumer group)

如何做到消息不丢失  
==
* ACK 机制  
>通过 ACK 机制保证消息送达。Kafka 采用的是至少一次（At least once），消息不会丢，但是可能会重复传输  

* 发送消息   
>为了得到更好的性能，Kafka 支持在生产者一侧进行本地buffer，<br>
>也就是累积到一定的条数才发送，如果这里设置不当是会丢消息的。<br>
>生产者端设置 producer.type=async, sync，默认是 sync。<br>
>当设置为 async，会大幅提升性能，因为生产者会在本地缓冲消息，并适时批量发送。<br>
>如果对可靠性要求高，那么这里可以设置为 sync 同步发送。<br>

* 消费消息<br>
>如果更注重可靠性，则需要显示提交 Offset，也就是当所有业务都处理完成的时候，再提交Offset。<br>
>这样会导致重复消费，需要提供幂等性接口。通过增加消费组的消费者来进行水平扩展提升消费能力。<br>
>这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。<br>
>另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。<br>
<br>

== https://www.jianshu.com/p/818826aa4e45
为什么 Kafka 性能高？

架构层面
   1.ISR-可用性和一致性的动态平衡
    Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。
        从一这点来讲，Kafka的数据复制方案接近于Master-Slave方案。
        不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。
    ISR，也即In-sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，
        包含了所有与之同步的Replica（包含Leader自己）。
        每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。
    这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，
        它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。
        每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。
    
   2.利用partiton并行处理
    kafka每个Topic都包含一个或多个Partition，不同Partition可位于不同节点。
    同时Partition在物理上对应一个本地文件夹，每个Partition包含一个或多个Segment，
        每个Segment包含一个数据文件和一个与之对应的索引文件。
        在逻辑上，可以把一个Partition当作一个非常长的数组，可通过这个“数组”的索引（offset）去访问其数据。
    一方面，由于不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。
    另一方面，由于Partition在物理上对应一个文件夹，即使多个Partition位于同一个节点，
    也可通过配置让同一节点上的不同Partition置于不同的disk drive上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

具体实现层面       
* 顺序写磁盘 
>顺序写磁盘的性能是随机写入的性能的6000倍的提升，媲美内存随机访问的性能，磁盘不再是瓶颈点。<br>
    Kafka的整个设计中，Partition相当于一个非常长的数组，而Broker接收到的所有消息顺序写入这个大数组中。
    同时Consumer通过Offset顺序消费这些数据，并且不删除已经消费的数据，从而避免了随机写磁盘的过程。
    由于磁盘有限，不可能保存所有数据，实际上作为消息系统Kafka也没必要保存所有数据，需要删除旧的数据。
    而这个删除过程，并非通过使用“读-写”模式去修改文件，而是将Partition分为多个Segment，每个Segment对应一个物理文件，
    通过删除整个文件的方式去删除Partition内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。

* Page Cache 
>为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。<br>
>通过操作系统的Page Cache，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。<br>
使用Page Cache的好处如下：
    1.I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能；
    2.I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间；
    3.充分利用所有空闲内存（非JVM内存）。如果使用应用层Cache（即JVM堆内存），会增加GC负担；
    4.读操作可直接在Page Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过Page Cache）交换数据；
    5.如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用。
    

* 零拷贝技术 
>零拷贝技术，可以有效的减少上下文切换和拷贝次数。<br>
>kafka的设计实现，涉及到很多的底层技术，为了能够把它吃透，需要花大量的时间，大量的精力。
    Kafka中存在大量的网络数据持久化到磁盘（Producer到Broker）和磁盘文件通过网络发送（Broker到Consumer）的过程。
    这一过程的性能直接影响Kafka的整体吞吐量。>
   Linux 2.4+内核通过sendfile系统调用，提供了零拷贝。
    数据通过DMA拷贝到内核态Buffer后，直接通过DMA拷贝到NIC Buffer，无需CPU拷贝。
    除了减少数据拷贝外，因为整个读文件-网络发送由一个sendfile调用完成，整个过程只有两次上下文切换，因此大大提高了性能。
    注： transferTo和transferFrom并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，
       如果操作系统提供sendfile这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，
       否则并不能通过这两个方法本身实现零拷贝。

* 支持多Disk Drive
    Broker的log.dirs配置项，允许配置多个文件夹。如果机器上有多个Disk Drive，可将不同的Disk挂载到不同的目录，
        然后将这些目录都配置到log.dirs里。
        Kafka会尽可能将不同的Partition分配到不同的目录，也即不同的Disk上，从而充分利用了多Disk的优势。

减少网络开销
    1.批处理
        将同步Producer和异步Producer结合,send方法并非立即将消息发送出去，
            而是通过batch.size和linger.ms控制实际发送频率，从而实现批量发送。
    2.数据压缩，降低网络负载
    3.高效的序列化方式



Kafka一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息。换句话说，每个应用都可以读到全量的消息。
为了使得每个应用都能读到全量消息，应用需要有不同的消费组。
  比如：订单生产后，产生了一条消息==>后续  【库存】需要消费当前的消息，【积分】也需要~


![多分组](https://github.com/percyqq/start/blob/master/pic/kafka%20group.png?raw=true)

消费组与分区重平衡
可以看到，当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；
另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为重平衡（rebalance）。

重平衡是Kafka一个很重要的性质，这个性质保证了高可用和水平扩展。
不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。
而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能






